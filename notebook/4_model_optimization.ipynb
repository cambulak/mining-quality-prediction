{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-19T19:29:46.728103Z",
     "start_time": "2025-11-19T19:18:07.743835Z"
    }
   },
   "source": [
    "# Hücre 1: Kütüphaneler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import optuna\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import joblib # Modeli kaydetmek için\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Hücre 2: Veri Yükleme ve Feature Engineering (Önceki adımın aynısı)\n",
    "df = pd.read_csv(r'C:\\Users\\Sedat\\PycharmProjects\\mining-quality-prediction\\data\\MiningProcess_Flotation_Plant_Database.csv', decimal=',')\n",
    "df.columns = [col.replace(' ', '_').replace('%_', '').replace('(', '').replace(')', '') for col in df.columns]\n",
    "df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "df = df.sort_values('date')\n",
    "\n",
    "# Feature Engineering (Lag ve Rolling)\n",
    "input_cols = [col for col in df.columns if col not in ['date', 'Silica_Concentrate']]\n",
    "for col in input_cols:\n",
    "    df[f'{col}_Rolling_Mean'] = df[col].rolling(window=5).mean()\n",
    "    df[f'{col}_Lag1'] = df[col].shift(1)\n",
    "\n",
    "df = df.dropna()\n",
    "\n",
    "# Veriyi Ayırma\n",
    "X = df.drop(['date', 'Silica_Concentrate'], axis=1)\n",
    "y = df['Silica_Concentrate']\n",
    "\n",
    "# XGBoost için validasyon setine de ihtiyacımız var\n",
    "# %80 Train, %10 Validation, %10 Test yapacağız\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.1, shuffle=False, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.11, shuffle=False, random_state=42)\n",
    "# 0.11 matematiksel olarak kalanın %10'una denk gelir yaklaşık\n",
    "\n",
    "print(f\"Train: {X_train.shape}, Val: {X_val.shape}, Test: {X_test.shape}\")\n",
    "\n",
    "# Hücre 3: Optuna ile Hiperparametre Arama\n",
    "# Optuna, en iyi parametreleri bulmak için yüzlerce deneme yapar.\n",
    "\n",
    "def objective(trial):\n",
    "    # Denenecek parametre aralıkları\n",
    "    params = {\n",
    "        'objective': 'reg:squarederror',\n",
    "        'eval_metric': 'rmse',\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0, 10),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 0, 10),\n",
    "        'tree_method': 'hist', # Hızlandırmak için\n",
    "        'device': 'cpu' # Eğer GPU varsa 'cuda' yapabilirsin\n",
    "    }\n",
    "\n",
    "    model = xgb.XGBRegressor(**params, random_state=42)\n",
    "    model.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=False)\n",
    "\n",
    "    preds = model.predict(X_val)\n",
    "    rmse = np.sqrt(mean_squared_error(y_val, preds))\n",
    "\n",
    "    return rmse\n",
    "\n",
    "print(\"Optuna optimizasyonu başlıyor... (Bu işlem 2-3 dakika sürebilir)\")\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=20) # 20 deneme yapacağız (Daha iyi sonuç için 50-100 yapılabilir)\n",
    "\n",
    "print(\"\\nEn İyi Parametreler:\")\n",
    "print(study.best_params)\n",
    "\n",
    "# Hücre 4: En İyi Parametrelerle Final Modeli Eğitme\n",
    "best_params = study.best_params\n",
    "final_model = xgb.XGBRegressor(**best_params, random_state=42)\n",
    "\n",
    "print(\"\\nFinal model eğitiliyor...\")\n",
    "final_model.fit(X_train, y_train)\n",
    "\n",
    "# Test Seti Üzerinde Sonuçlar\n",
    "y_pred = final_model.predict(X_test)\n",
    "final_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "final_r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"--- XGBoost Optuna Sonuçları ---\")\n",
    "print(f\"Final R2 Score: {final_r2:.4f}\")\n",
    "print(f\"Final RMSE: {final_rmse:.4f}\")\n",
    "\n",
    "# Hücre 5: Modeli Kaydet (Deployment için lazım olacak)\n",
    "joblib.dump(final_model, '../models/final_xgboost_model.pkl')\n",
    "print(\"Model '../models/' klasörüne kaydedildi.\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-19 22:18:11,678] A new study created in memory with name: no-name-8b5f3bb4-1a66-4c84-ad05-4176c140d28a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (590696, 66), Val: (73008, 66), Test: (73745, 66)\n",
      "Optuna optimizasyonu başlıyor... (Bu işlem 2-3 dakika sürebilir)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-19 22:19:29,412] Trial 0 finished with value: 0.7764805364391663 and parameters: {'n_estimators': 770, 'max_depth': 8, 'learning_rate': 0.1772136557187996, 'subsample': 0.6820906497847694, 'colsample_bytree': 0.9732893369499102, 'reg_alpha': 4.101230655582514, 'reg_lambda': 9.723449417030173}. Best is trial 0 with value: 0.7764805364391663.\n",
      "[I 2025-11-19 22:19:43,768] Trial 1 finished with value: 0.7112305960866042 and parameters: {'n_estimators': 209, 'max_depth': 5, 'learning_rate': 0.02610586158751911, 'subsample': 0.7544633968375494, 'colsample_bytree': 0.8104822462902593, 'reg_alpha': 4.216537975508146, 'reg_lambda': 3.846481680451308}. Best is trial 1 with value: 0.7112305960866042.\n",
      "[I 2025-11-19 22:20:39,061] Trial 2 finished with value: 0.7713035046026837 and parameters: {'n_estimators': 873, 'max_depth': 6, 'learning_rate': 0.04899940035075583, 'subsample': 0.7117565072443119, 'colsample_bytree': 0.6653999446656195, 'reg_alpha': 4.603973627671058, 'reg_lambda': 8.73465545322821}. Best is trial 1 with value: 0.7112305960866042.\n",
      "[I 2025-11-19 22:21:15,723] Trial 3 finished with value: 0.7871904504210608 and parameters: {'n_estimators': 490, 'max_depth': 7, 'learning_rate': 0.20223086451422168, 'subsample': 0.7319357661647313, 'colsample_bytree': 0.809747899407364, 'reg_alpha': 2.085230872974515, 'reg_lambda': 5.799283860387533}. Best is trial 1 with value: 0.7112305960866042.\n",
      "[I 2025-11-19 22:21:50,274] Trial 4 finished with value: 0.790881942748651 and parameters: {'n_estimators': 287, 'max_depth': 9, 'learning_rate': 0.05902572859486675, 'subsample': 0.6956533229409104, 'colsample_bytree': 0.9801019121642816, 'reg_alpha': 1.6731165526909386, 'reg_lambda': 8.220483468839777}. Best is trial 1 with value: 0.7112305960866042.\n",
      "[I 2025-11-19 22:22:24,483] Trial 5 finished with value: 0.8082716575018282 and parameters: {'n_estimators': 732, 'max_depth': 4, 'learning_rate': 0.2990931040148635, 'subsample': 0.6978277072780336, 'colsample_bytree': 0.9967002270500014, 'reg_alpha': 0.8595192808640051, 'reg_lambda': 1.4865324992618267}. Best is trial 1 with value: 0.7112305960866042.\n",
      "[I 2025-11-19 22:22:59,519] Trial 6 finished with value: 0.7770705692820172 and parameters: {'n_estimators': 489, 'max_depth': 7, 'learning_rate': 0.2347728213677556, 'subsample': 0.9364941787113087, 'colsample_bytree': 0.7661295176893642, 'reg_alpha': 0.8124255245917378, 'reg_lambda': 8.921872663647614}. Best is trial 1 with value: 0.7112305960866042.\n",
      "[I 2025-11-19 22:23:34,036] Trial 7 finished with value: 0.7087840243222642 and parameters: {'n_estimators': 814, 'max_depth': 3, 'learning_rate': 0.04391546030163544, 'subsample': 0.7072420661612152, 'colsample_bytree': 0.6874523771884891, 'reg_alpha': 2.6649955595443497, 'reg_lambda': 8.344839349580123}. Best is trial 7 with value: 0.7087840243222642.\n",
      "[I 2025-11-19 22:24:12,035] Trial 8 finished with value: 0.7807617977525321 and parameters: {'n_estimators': 482, 'max_depth': 8, 'learning_rate': 0.08749941182095167, 'subsample': 0.9790775734064898, 'colsample_bytree': 0.6248811494463739, 'reg_alpha': 6.812849119607446, 'reg_lambda': 8.277870331769567}. Best is trial 7 with value: 0.7087840243222642.\n",
      "[I 2025-11-19 22:24:46,716] Trial 9 finished with value: 0.7846035771243307 and parameters: {'n_estimators': 309, 'max_depth': 9, 'learning_rate': 0.16434684726442658, 'subsample': 0.6568814556110307, 'colsample_bytree': 0.9866709162561818, 'reg_alpha': 2.292349590184858, 'reg_lambda': 0.28903455241722553}. Best is trial 7 with value: 0.7087840243222642.\n",
      "[I 2025-11-19 22:25:26,578] Trial 10 finished with value: 0.7716960813840736 and parameters: {'n_estimators': 967, 'max_depth': 3, 'learning_rate': 0.11845058640360862, 'subsample': 0.8433153237103859, 'colsample_bytree': 0.715694717416246, 'reg_alpha': 9.231593092420646, 'reg_lambda': 6.380836357783495}. Best is trial 7 with value: 0.7087840243222642.\n",
      "[I 2025-11-19 22:25:35,240] Trial 11 finished with value: 0.7398598421194442 and parameters: {'n_estimators': 120, 'max_depth': 5, 'learning_rate': 0.0171957563813617, 'subsample': 0.8045602453353213, 'colsample_bytree': 0.8441262492667323, 'reg_alpha': 5.99534936363302, 'reg_lambda': 3.371321463888001}. Best is trial 7 with value: 0.7087840243222642.\n",
      "[I 2025-11-19 22:26:03,685] Trial 12 finished with value: 0.7126479177389838 and parameters: {'n_estimators': 658, 'max_depth': 3, 'learning_rate': 0.0185630183514496, 'subsample': 0.6101456025619513, 'colsample_bytree': 0.884661892340871, 'reg_alpha': 3.6574700865416565, 'reg_lambda': 4.143669224143027}. Best is trial 7 with value: 0.7087840243222642.\n",
      "[I 2025-11-19 22:26:11,123] Trial 13 finished with value: 0.7265523121621561 and parameters: {'n_estimators': 116, 'max_depth': 5, 'learning_rate': 0.08986865770859058, 'subsample': 0.7749058283953046, 'colsample_bytree': 0.727763981503876, 'reg_alpha': 7.371054597223762, 'reg_lambda': 3.0575999346427136}. Best is trial 7 with value: 0.7087840243222642.\n",
      "[I 2025-11-19 22:26:25,754] Trial 14 finished with value: 0.7479288880257128 and parameters: {'n_estimators': 303, 'max_depth': 4, 'learning_rate': 0.10735545579980607, 'subsample': 0.8745025524166306, 'colsample_bytree': 0.899946558732723, 'reg_alpha': 3.339098036326275, 'reg_lambda': 6.805053944845435}. Best is trial 7 with value: 0.7087840243222642.\n",
      "[I 2025-11-19 22:26:57,764] Trial 15 finished with value: 0.7539524875393342 and parameters: {'n_estimators': 627, 'max_depth': 5, 'learning_rate': 0.05325027760294295, 'subsample': 0.7824342847194445, 'colsample_bytree': 0.6876287033129738, 'reg_alpha': 5.04682086816891, 'reg_lambda': 4.747150663181323}. Best is trial 7 with value: 0.7087840243222642.\n",
      "[I 2025-11-19 22:27:37,901] Trial 16 finished with value: 0.7791937764290353 and parameters: {'n_estimators': 861, 'max_depth': 4, 'learning_rate': 0.12997514774350888, 'subsample': 0.628692933834343, 'colsample_bytree': 0.6034137817221401, 'reg_alpha': 5.5936037228754625, 'reg_lambda': 2.5672252823877457}. Best is trial 7 with value: 0.7087840243222642.\n",
      "[I 2025-11-19 22:27:56,136] Trial 17 finished with value: 0.7145159793528011 and parameters: {'n_estimators': 383, 'max_depth': 3, 'learning_rate': 0.015279116579298136, 'subsample': 0.7531200741647145, 'colsample_bytree': 0.7764006063062572, 'reg_alpha': 2.969928667676372, 'reg_lambda': 7.492412144394384}. Best is trial 7 with value: 0.7087840243222642.\n",
      "[I 2025-11-19 22:28:51,137] Trial 18 finished with value: 0.7964272077323523 and parameters: {'n_estimators': 975, 'max_depth': 6, 'learning_rate': 0.06972182175165001, 'subsample': 0.8480032973693418, 'colsample_bytree': 0.739330589381126, 'reg_alpha': 0.18238512481036295, 'reg_lambda': 5.323954006498899}. Best is trial 7 with value: 0.7087840243222642.\n",
      "[I 2025-11-19 22:29:18,250] Trial 19 finished with value: 0.7838778346143893 and parameters: {'n_estimators': 206, 'max_depth': 10, 'learning_rate': 0.13229982116207106, 'subsample': 0.8094932495400006, 'colsample_bytree': 0.8408222330822451, 'reg_alpha': 8.410669438038525, 'reg_lambda': 1.9419377299575724}. Best is trial 7 with value: 0.7087840243222642.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "En İyi Parametreler:\n",
      "{'n_estimators': 814, 'max_depth': 3, 'learning_rate': 0.04391546030163544, 'subsample': 0.7072420661612152, 'colsample_bytree': 0.6874523771884891, 'reg_alpha': 2.6649955595443497, 'reg_lambda': 8.344839349580123}\n",
      "\n",
      "Final model eğitiliyor...\n",
      "--- XGBoost Optuna Sonuçları ---\n",
      "Final R2 Score: 0.6785\n",
      "Final RMSE: 0.6715\n",
      "Model '../models/' klasörüne kaydedildi.\n"
     ]
    }
   ],
   "execution_count": 2
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
